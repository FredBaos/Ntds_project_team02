Welcome to our project repository for the Network Tour of Data Science course at EPFL !

We implemented a query-based search engine for Wikipedia articles related to various Machine Learning topics. That is given a query our system will retrieve and suggest articles with similar semantic contents. Moreover, we provide a graph visualisation tool to interact with the query engine.

More details about this ML system can be found in the project report.

## How to reproduce results:
- Specify INITIAL_FILENAME in config.py. This is the path to the dataset produced at Seealsology.com. The seeds to scrap the graph are given in the seeds_seealsology.txt file (use a max distance of 2).
- Download the “wiki-news-300d-1M-subword.magnitude” file at magnitude.github.com  and put it into the data folder.
- export PYTHONPATH=wd where wd is the directory containing the run.sh script.
- Execute the run.sh script.

## Files breakdown:

run.sh: shell script executing the acquisition, exploitation and visualisation tasks.

Acquisition:
- acquisition_helpers.py:  various helpers
- acquisition.py: loads the dataset and augments it with urls and keywords extraction

Exploration.ipynb: exploratory data analysis.

Exploitation:
- exploitation.py: fits and saves the 3 models we used
- exploitation.ipynb: loads the models and performs a qualitative evaluation on a set of queries and topics

Visualization:
- app.py: runs the visualisation app on a dedicated server
- create_visu.py: creates and saves the graph visualisation
- utils.py: various helpers

Helpers:
- predict.py: helpers for the exploitation part
- spectral_clustering: specific helpers for the spectral clustering model

Data: contains every file loaded and generated by the different modules.


