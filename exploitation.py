# Imports
import networkx as nx
import pandas as pd
import numpy as np
import random
import pickle
import re
from operator import itemgetter
from gensim.models import Word2Vec
from node2vec import Node2Vec
from config import *
from transformers import *
from spectral_clustering import *
from pymagnitude import *
from predict import *
from ast import literal_eval

random.seed(1)
numpy.random.seed(1)

edge_list = pd.read_csv("ml-nlp-ai-ann-chatbot-ia-dataviz-dist2.tsv", sep = "\t")
df_node = pd.read_csv(DF_NODE_FILENAME)
df_node['keywords'] = df_node['keywords'].apply(literal_eval)
df_edge = pd.read_csv(DF_EDGE_FILENAME)
graph = nx.from_pandas_edgelist(edge_list, "source", "target", edge_attr=True)

node2vec = Node2Vec(graph, walk_length=40, num_walks=10, quiet=True, p=1, q=1)
node2vec_model = node2vec.fit(window=5, size=100, min_count=5, sg=1, hs=0, negative=10, iter=20)
node2vec_model.save(NODE2VEC_FILENAME)

ordered_nodes = list(sorted(graph.nodes()))
A = nx.adjacency_matrix(graph,nodelist=ordered_nodes)
proj = laplacian_eigenmaps(A,dim=100,sigma=None,epsilon=None,normalize=None,use_similarity=False)

name2idx_adjacency = {}
idx = 0
for node in ordered_nodes:
    name2idx_adjacency[node] = idx
    idx += 1
    
with open(SPECTRAL_CLUSTERING_FILENAME,'wb') as f:
    pickle.dump(proj,f)
    pickle.dump(ordered_nodes,f)
    pickle.dump(name2idx_adjacency,f)

walks = node2vec.walks

mean_embeddings_fastt = [fastt_embedding(' '.join(words_ls) + ' ' + title) for words_ls, title in zip(df_node['keywords'], df_node['name'])]
embeddings_dict_fastt = dict(zip(list(df_node.name.values), mean_embeddings_fastt))
walk_averaged_embeddings_dict_fastt = walk_averaged_embeddings_dict(embeddings_dict_fastt, walks, source_weight=0.75)

with open(FAST_MEAN_FILENAME,'wb') as f:
    pickle.dump(walk_averaged_embeddings_dict_fastt,f)
    
