{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import wikipedia\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from config import *\n",
    "from transformers import *\n",
    "from spectral_clustering import *\n",
    "from pymagnitude import *\n",
    "from predict import *\n",
    "from pprint import pprint\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  1166\n"
     ]
    }
   ],
   "source": [
    "# Loading dataframes and building graph\n",
    "edge_list = pd.read_csv(\"ml-nlp-ai-ann-chatbot-ia-dataviz-dist2.tsv\", sep = \"\\t\")\n",
    "df_node = pd.read_csv(DF_NODE_FILENAME)\n",
    "df_node['keywords'] = df_node['keywords'].apply(literal_eval)\n",
    "df_edge = pd.read_csv(DF_EDGE_FILENAME)\n",
    "graph = nx.from_pandas_edgelist(edge_list, \"source\", \"target\", edge_attr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one article queries\n",
    "query_1 = 'machine learning'\n",
    "query_2 = 'data visualization'\n",
    "query_3 = 'natural language processing'\n",
    "query_4 = 'artificial intelligence'\n",
    "\n",
    "# many articles queries\n",
    "query_5 = 'data visualization,machine learning'\n",
    "query_6 = 'artificial intelligence,natural language processing'\n",
    "query_7 = 'social simulation,intelligent agent,chat bot'\n",
    "\n",
    "# illustrating the pros of fasttext\n",
    "query_8 = 'what is machine learning' # sentence like query\n",
    "query_9 = 'money money money' # abba lyrics query\n",
    "query_10 = 'automated learning' # non referenced article\n",
    "query_11 = 'machine learning language processing' # referenced + non referenced articles\n",
    "\n",
    "all_queries = [query_1,query_2,query_3,query_4,query_5,query_6,query_7,query_8,query_9,query_10,query_11]\n",
    "\n",
    "\n",
    "cluster_1 = ['neural architecture search', 'hyperparameter optimization', 'model selection', \n",
    "             'self-tuning', 'automated machine learning']\n",
    "\n",
    "cluster_2 = ['data visualization', 'data art', 'visual analytics', 'exploratory data analysis',\n",
    "             'information visualization']\n",
    "\n",
    "cluster_3 = ['machine learning', 'artificial intelligence', 'genetic algorithm', 'evolutionary computation',\n",
    "             'reinforcement learning']\n",
    "\n",
    "cluster_4 = ['natural language processing', 'latent dirichlet allocation', 'word2vec', 'speech processing',\n",
    "             'information retrieval']\n",
    "\n",
    "cluster_5 = ['convolutional neural network', 'deep learning', 'artificial neural network',\n",
    "             'computational neuroscience', 'blue brain project']\n",
    "\n",
    "cluster_6 = ['universal basic income', 'mincome', 'minimum wage', 'quatinga velho', 'job guarantee']\n",
    "\n",
    "nodes_to_plot = cluster_1 + cluster_2 + cluster_3 + cluster_4 + cluster_5 + cluster_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node to vector representations\n",
    "\n",
    "Algorithms:\n",
    "- Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(graph, walk_length=40, num_walks=10, quiet=True, p=1, q=1)\n",
    "# For small datasets Skip-gram and 10-20 negative samples are recommended\n",
    "node2vec_model = node2vec.fit(window=5, size=100, min_count=5, sg=1, hs=0, negative=10, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec_model.save(NODE2VEC_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_vectors = node2vec_model.wv[nodes_to_plot]\n",
    "plot_projection(node_vectors, nodes_to_plot, 'clustering_evaluation/node2vec_pca')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(node_vectors, nodes_to_plot, 'clustering_evaluation/node2vec_tsne', projection_method=TSNE, perplexity=2)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral clustering on hyperlink graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_nodes = list(sorted(graph.nodes()))\n",
    "A = nx.adjacency_matrix(graph,nodelist=ordered_nodes)\n",
    "proj = laplacian_eigenmaps(A,dim=100,sigma=None,epsilon=None,normalize=None,use_similarity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2idx_adjacency = {}\n",
    "idx = 0\n",
    "for node in ordered_nodes:\n",
    "    name2idx_adjacency[node] = idx\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SPECTRAL_CLUSTERING_FILENAME,'wb') as f:\n",
    "    pickle.dump(proj,f)\n",
    "    pickle.dump(ordered_nodes,f)\n",
    "    pickle.dump(name2idx_adjacency,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_vectors = get_vectors_spectral(nodes_to_plot,proj,name2idx_adjacency)\n",
    "plot_projection(node_vectors, nodes_to_plot, 'clustering_evaluation/spectral_pca')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(node_vectors, nodes_to_plot, 'clustering_evaluation/spectral_tsne', projection_method=TSNE, perplexity=3)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Node attributes and graph structure\n",
    "\n",
    "- Obtain representations of keywords extracted from summaries as fasttext embeddings\n",
    "- Perform walks and average embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(graph, walk_length=40, num_walks=10, quiet=True, p=1, q=1)\n",
    "walks = node2vec.walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embeddings_fastt = [fastt_embedding(' '.join(words_ls) + ' ' + title) for words_ls, title in zip(df_node['keywords'], df_node['name'])]\n",
    "embeddings_dict_fastt = dict(zip(list(df_node.name.values), mean_embeddings_fastt))\n",
    "walk_averaged_embeddings_dict_fastt = walk_averaged_embeddings_dict(embeddings_dict_fastt, walks, source_weight=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FAST_MEAN_FILENAME,'wb') as f:\n",
    "    pickle.dump(walk_averaged_embeddings_dict_fastt,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_vectors = get_vectors_fasttext(nodes_to_plot,walk_averaged_embeddings_dict_fastt)\n",
    "plot_projection(node_vectors, nodes_to_plot, 'clustering_evaluation/fastt_pca')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection(node_vectors, nodes_to_plot, 'clustering_evaluation/fastt_tsne', projection_method=TSNE, perplexity=2)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_queries_print(all_queries):\n",
    "    for query in all_queries:\n",
    "        print(\"\\n----------\\n\")\n",
    "        print(query)\n",
    "        print(\"Node2Vec\")\n",
    "        pprint((query_answers_node2vec(query, node2vec_model, df_node, 10, return_idx=False)))\n",
    "        print(\"Spectral\")\n",
    "        pprint(query_answers_spectral(query, proj, ordered_nodes, df_node, name2idx_adjacency, topn=10, return_idx=False))\n",
    "        print(\"FastText\")\n",
    "        pprint((query_answers_fasttext(query,vectors,walk_averaged_embeddings_dict_fastt,df_node,topn=10, return_idx=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "all_queries_print(all_queries)\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
